# Quick Start Guide - MLOps Face Attribute Classification

## ğŸš€ DÃ©marrage Rapide

Ce guide vous permettra de dÃ©marrer rapidement avec le projet.

## ğŸ“‹ PrÃ©requis

- Python 3.10+
- Docker et Docker Compose
- Git
- 4GB+ RAM disponible

## âš¡ Installation en 5 Minutes

### 1. Cloner le Repository

```bash
git clone https://github.com/omdrift/mlops_face_attribute_classification.git
cd mlops_face_attribute_classification
```

### 2. Installer les DÃ©pendances Python

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 3. Configurer DVC (Optionnel)

```bash
# Configurer un remote local (pour tests)
dvc remote add -d storage /tmp/dvc-storage

# Ou configurer S3 (pour production)
# dvc remote add -d s3storage s3://my-bucket/dvc-storage
# dvc remote modify s3storage region us-east-1
```

### 4. DÃ©marrer Airflow

```bash
# Initialiser Airflow
./scripts/init_airflow.sh

# DÃ©marrer les services
docker-compose up -d

# VÃ©rifier que tout fonctionne
docker-compose ps
```

### 5. AccÃ©der Ã  Airflow

Ouvrez votre navigateur: http://localhost:8080

- Username: `airflow`
- Password: `airflow`

## ğŸ¯ Premiers Pas

### ExÃ©cuter le Pipeline ML

#### Option 1: Avec Airflow (RecommandÃ©)

1. Ouvrez l'interface Airflow: http://localhost:8080
2. Activez le DAG `ml_pipeline_face_attributes`
3. Cliquez sur "Trigger DAG" pour dÃ©marrer

#### Option 2: Avec DVC (Manuel)

```bash
# Reproduire tout le pipeline
dvc repro

# Ou Ã©tape par Ã©tape
dvc repro prepare_train
dvc repro hyperopt
dvc repro train
dvc repro evaluate
```

### Voir les RÃ©sultats

```bash
# MÃ©triques
cat metrics/train_metrics.json
cat metrics/eval_metrics.json

# Visualisations
ls plots/

# Avec DVC
dvc metrics show
dvc plots show
```

## ğŸ“Š Structure du Projet (SimplifiÃ©)

```
.
â”œâ”€â”€ airflow/              # Orchestration Airflow
â”‚   â””â”€â”€ dags/             # DAGs Airflow
â”œâ”€â”€ data/                 # DonnÃ©es (gÃ©rÃ© par DVC)
â”œâ”€â”€ src/                  # Code source
â”‚   â”œâ”€â”€ data/             # PrÃ©paration des donnÃ©es
â”‚   â”œâ”€â”€ models/           # Architecture du modÃ¨le
â”‚   â””â”€â”€ training/         # EntraÃ®nement et Ã©valuation
â”œâ”€â”€ models/               # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ metrics/              # MÃ©triques JSON
â”œâ”€â”€ plots/                # Visualisations
â”œâ”€â”€ scripts/              # Scripts utiles
â”œâ”€â”€ dvc.yaml              # Pipeline DVC
â”œâ”€â”€ params.yaml           # ParamÃ¨tres
â””â”€â”€ docker-compose.yml    # Configuration Airflow
```

## ğŸ”§ Configuration Rapide

### Modifier les HyperparamÃ¨tres

Ã‰ditez `params.yaml`:

```yaml
train:
  epochs: 20        # Changer de 10 Ã  20
  batch_size: 64    # Changer de 32 Ã  64
```

Puis relancez:

```bash
dvc repro
# ou via Airflow
```

### Configurer les Notifications Email

Dans `docker-compose.yml`:

```yaml
environment:
  AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
  AIRFLOW__SMTP__SMTP_USER: your_email@gmail.com
  AIRFLOW__SMTP__SMTP_PASSWORD: your_app_password
```

## ğŸ“– Documentation ComplÃ¨te

- [README Principal](README.md) - Vue d'ensemble complÃ¨te
- [Guide DVC](docs/DVC_BEST_PRACTICES.md) - Bonnes pratiques DVC
- [Guide Airflow](docs/AIRFLOW_GUIDE.md) - Documentation Airflow

## ğŸ› ï¸ Commandes Utiles

### DVC

```bash
# Helper DVC
./scripts/dvc_helper.sh status       # Statut du pipeline
./scripts/dvc_helper.sh repro        # Reproduire le pipeline
./scripts/dvc_helper.sh metrics      # Voir les mÃ©triques
./scripts/dvc_helper.sh plots        # GÃ©nÃ©rer les plots
```

### Airflow

```bash
# Voir les logs
docker-compose logs -f

# RedÃ©marrer un service
docker-compose restart airflow-scheduler

# ArrÃªter tout
docker-compose down
```

### Pipeline ML

```bash
# EntraÃ®ner le modÃ¨le
python src/training/train.py

# Ã‰valuer le modÃ¨le
python src/training/evaluate.py

# Optimiser les hyperparamÃ¨tres
python src/training/hyperopt_search.py --max-evals 10
```

## ğŸ› DÃ©pannage Rapide

### Airflow ne dÃ©marre pas

```bash
docker-compose down -v
./scripts/init_airflow.sh
docker-compose up -d
```

### Erreur "DVC not found"

```bash
pip install dvc
```

### Erreur "Data not found"

```bash
# Si vous avez configurÃ© un remote
dvc pull

# Sinon, assurez-vous que data/raw existe
```

### Port 8080 dÃ©jÃ  utilisÃ©

Modifiez dans `docker-compose.yml`:

```yaml
ports:
  - "8081:8080"  # Utilisez 8081 au lieu de 8080
```

## ğŸ’¡ Prochaines Ã‰tapes

1. **Explorer les DAGs Airflow**
   - `ml_pipeline_face_attributes`: Pipeline principal
   - `model_monitoring_and_retraining`: Surveillance automatique

2. **ExpÃ©rimenter avec DVC**
   ```bash
   # Tester diffÃ©rents paramÃ¨tres
   dvc exp run -S train.epochs=20 -S train.batch_size=64
   
   # Comparer les rÃ©sultats
   dvc exp show
   ```

3. **Configurer le Remote Storage**
   - Pour partager les donnÃ©es avec l'Ã©quipe
   - S3, GCS, Azure, ou stockage local partagÃ©

4. **Personnaliser les DAGs**
   - Ajouter vos propres Ã©tapes
   - Configurer les notifications
   - Ajuster les planifications

## ğŸ“ Support

Pour plus d'informations:

- [Documentation DVC](https://dvc.org/doc)
- [Documentation Airflow](https://airflow.apache.org/docs/)
- Issues GitHub: https://github.com/omdrift/mlops_face_attribute_classification/issues

## âœ… Checklist de VÃ©rification

- [ ] Python installÃ© et environnement virtuel crÃ©Ã©
- [ ] DÃ©pendances installÃ©es (`pip install -r requirements.txt`)
- [ ] Docker et Docker Compose installÃ©s
- [ ] Airflow dÃ©marrÃ© et accessible (http://localhost:8080)
- [ ] DAG visible dans l'interface Airflow
- [ ] Pipeline DVC testÃ© (`dvc status`)
- [ ] Documentation lue (README.md)

Vous Ãªtes prÃªt! ğŸ‰
