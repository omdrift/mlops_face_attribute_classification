# MLOps Face Attribute Classification

Projet de classification d'attributs faciaux utilisant les meilleures pratiques MLOps avec DVC et Apache Airflow.

## ğŸ¯ Objectif du Projet

Ce projet implÃ©mente un pipeline complet de Machine Learning pour la classification d'attributs faciaux:
- Barbe (beard)
- Moustache (mustache)
- Lunettes (glasses)
- Couleur des cheveux (hair_color)
- Longueur des cheveux (hair_length)

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ airflow/                    # Configuration Apache Airflow
â”‚   â”œâ”€â”€ dags/                   # DAGs Airflow
â”‚   â”‚   â”œâ”€â”€ ml_pipeline_dag.py      # Pipeline ML principal
â”‚   â”‚   â””â”€â”€ monitoring_dag.py       # Surveillance et rÃ©-entraÃ®nement
â”‚   â”œâ”€â”€ logs/                   # Logs Airflow
â”‚   â”œâ”€â”€ plugins/                # Plugins personnalisÃ©s
â”‚   â””â”€â”€ config/                 # Configuration Airflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # DonnÃ©es brutes (gÃ©rÃ© par DVC)
â”‚   â”œâ”€â”€ processed/              # DonnÃ©es prÃ©traitÃ©es
â”‚   â””â”€â”€ annotations/            # Fichiers d'annotations
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                   # Scripts de prÃ©paration des donnÃ©es
â”‚   â”œâ”€â”€ models/                 # Architecture du modÃ¨le
â”‚   â”œâ”€â”€ training/               # Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ inference/              # Scripts d'infÃ©rence
â”‚   â””â”€â”€ utils/                  # Utilitaires
â”œâ”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ metrics/                    # MÃ©triques d'Ã©valuation
â”œâ”€â”€ plots/                      # Visualisations
â”œâ”€â”€ notebooks/                  # Notebooks Jupyter
â”œâ”€â”€ dvc.yaml                    # Pipeline DVC
â”œâ”€â”€ params.yaml                 # ParamÃ¨tres du projet
â”œâ”€â”€ docker-compose.yml          # Configuration Docker pour Airflow
â””â”€â”€ requirements.txt            # DÃ©pendances Python
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10+
- pip
- Docker et Docker Compose (pour Airflow)
- Git

### Installation des dÃ©pendances

```bash
# Cloner le repository
git clone https://github.com/omdrift/mlops_face_attribute_classification.git
cd mlops_face_attribute_classification

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“Š Utilisation de DVC

### Configuration initiale

```bash
# Initialiser DVC (dÃ©jÃ  fait)
dvc init

# Configurer un remote storage (optionnel mais recommandÃ©)
# Option 1: Stockage local
dvc remote add -d storage /path/to/storage

# Option 2: Stockage S3
dvc remote add -d s3storage s3://my-bucket/dvc-storage
dvc remote modify s3storage region us-east-1

# Option 3: Google Drive
dvc remote add -d gdrive gdrive://your-folder-id
```

### Gestion des donnÃ©es

```bash
# TÃ©lÃ©charger les donnÃ©es depuis le remote
dvc pull

# Ajouter de nouvelles donnÃ©es
dvc add data/raw
git add data/raw.dvc .gitignore
git commit -m "Add new raw data"

# Pousser les donnÃ©es vers le remote
dvc push
```

### ExÃ©cution du pipeline

```bash
# Reproduire tout le pipeline
dvc repro

# Reproduire une Ã©tape spÃ©cifique
dvc repro prepare_train
dvc repro hyperopt
dvc repro train
dvc repro evaluate

# Voir le graphe du pipeline
dvc dag

# Comparer les mÃ©triques entre versions
dvc metrics show
dvc metrics diff
```

### Visualisation des expÃ©riences

```bash
# Voir les diffÃ©rentes expÃ©riences
dvc exp show

# Comparer plusieurs expÃ©riences
dvc exp diff

# Visualiser les mÃ©triques et plots
dvc plots show

# Comparer les plots entre expÃ©riences
dvc plots diff
```

## ğŸ”„ Utilisation d'Apache Airflow

### DÃ©marrage d'Airflow avec Docker

```bash
# DÃ©marrer tous les services Airflow
docker-compose up -d

# VÃ©rifier l'Ã©tat des services
docker-compose ps

# Voir les logs
docker-compose logs -f

# ArrÃªter les services
docker-compose down
```

### AccÃ¨s Ã  l'interface Web

1. Ouvrez votre navigateur: http://localhost:8080
2. Connectez-vous avec:
   - Username: `airflow`
   - Password: `airflow`

### DAGs disponibles

#### 1. ml_pipeline_face_attributes
Pipeline principal qui exÃ©cute:
- âœ“ VÃ©rification de l'environnement
- âœ“ VÃ©rification des donnÃ©es brutes
- âœ“ PrÃ©paration des donnÃ©es (DVC)
- âœ“ Optimisation des hyperparamÃ¨tres
- âœ“ EntraÃ®nement du modÃ¨le
- âœ“ Ã‰valuation du modÃ¨le
- âœ“ Archivage des artifacts

**Planification**: Quotidienne (`@daily`)

#### 2. model_monitoring_and_retraining
Pipeline de surveillance qui:
- âœ“ VÃ©rifie les performances du modÃ¨le
- âœ“ DÃ©tecte le data drift
- âœ“ DÃ©clenche automatiquement le rÃ©-entraÃ®nement si nÃ©cessaire
- âœ“ Log les rÃ©sultats de la surveillance

**Planification**: Hebdomadaire (`@weekly`)

### ExÃ©cution manuelle d'un DAG

```bash
# Via l'interface web: cliquez sur le bouton "Trigger DAG"

# Via CLI (dans le container)
docker-compose exec airflow-scheduler airflow dags trigger ml_pipeline_face_attributes

# VÃ©rifier l'Ã©tat d'exÃ©cution
docker-compose exec airflow-scheduler airflow dags list-runs -d ml_pipeline_face_attributes
```

### Configuration personnalisÃ©e

Modifiez les variables d'environnement dans `docker-compose.yml`:

```yaml
environment:
  PROJECT_DIR: /opt/airflow/project
  PYTHONPATH: /opt/airflow/project
  # Ajoutez vos variables personnalisÃ©es ici
```

## ğŸ“ ParamÃ¨tres du Projet

Tous les paramÃ¨tres sont dÃ©finis dans `params.yaml`:

```yaml
hyperopt:
  max_evals: 10          # Nombre d'Ã©valuations Hyperopt
  timeout: 3600          # Timeout en secondes
  
train:
  epochs: 10             # Nombre d'Ã©poques
  batch_size: 32         # Taille du batch
  learning_rate: 0.001   # Taux d'apprentissage
  
data:
  image_size: 64         # Taille des images
  train_split: 0.8       # Proportion train
  val_split: 0.1         # Proportion validation
  test_split: 0.1        # Proportion test
```

Pour modifier les paramÃ¨tres:

```bash
# Ã‰diter params.yaml
nano params.yaml

# Rejouer le pipeline avec les nouveaux paramÃ¨tres
dvc repro

# Comparer les rÃ©sultats
dvc metrics diff
```

## ğŸ“ˆ MÃ©triques et Visualisations

### MÃ©triques gÃ©nÃ©rÃ©es

- `metrics/data_stats.json`: Statistiques sur les donnÃ©es
- `metrics/hyperopt_results.json`: RÃ©sultats de l'optimisation
- `metrics/train_metrics.json`: MÃ©triques d'entraÃ®nement
- `metrics/eval_metrics.json`: MÃ©triques d'Ã©valuation

### Visualisations gÃ©nÃ©rÃ©es

- `plots/data_distribution.png`: Distribution des attributs
- `plots/training_curves.png`: Courbes de loss
- `plots/accuracy_curves.png`: Courbes d'accuracy
- `plots/confusion_matrices.png`: Matrices de confusion
- `plots/roc_curves.png`: Courbes ROC

## ğŸ” Surveillance et Monitoring

### Logs de surveillance

Les logs de surveillance sont sauvegardÃ©s dans:
- `logs/monitoring_log.json`: Historique des vÃ©rifications
- `airflow/logs/`: Logs des DAGs Airflow

### Seuils de performance

Le modÃ¨le est considÃ©rÃ© comme nÃ©cessitant un rÃ©-entraÃ®nement si:
- Accuracy moyenne < 85% (configurable dans `monitoring_dag.py`)
- DÃ©tection de data drift

## ğŸ› ï¸ Bonnes Pratiques

### DVC

1. **Toujours versionner avec Git**: Commitez les fichiers `.dvc` et `dvc.lock`
2. **Utiliser un remote**: Configurez un remote storage pour partager les donnÃ©es
3. **ParamÃ©trer avec params.yaml**: Ã‰vitez les valeurs hardcodÃ©es
4. **Documenter les mÃ©triques**: Ajoutez des descriptions dans `dvc.yaml`
5. **Utiliser dvc experiments**: Pour tester rapidement diffÃ©rentes configurations

### Airflow

1. **Idempotence**: Les tÃ¢ches doivent pouvoir Ãªtre rejouÃ©es sans effets de bord
2. **Logging**: Loggez abondamment pour faciliter le debugging
3. **Task Groups**: Organisez les tÃ¢ches liÃ©es dans des groupes
4. **Sensors**: Utilisez des sensors pour attendre les dÃ©pendances
5. **Retry Strategy**: Configurez des retries appropriÃ©s pour les tÃ¢ches

### DÃ©veloppement

1. **Environnements virtuels**: Toujours utiliser un venv
2. **Tests**: Testez chaque Ã©tape du pipeline individuellement
3. **Documentation**: Documentez les changements importants
4. **Versioning**: Utilisez des tags Git pour les versions de production

## ğŸ› DÃ©pannage

### ProblÃ¨me: DVC ne trouve pas les donnÃ©es

```bash
# VÃ©rifier la configuration du remote
dvc remote list

# TÃ©lÃ©charger les donnÃ©es
dvc pull -v
```

### ProblÃ¨me: Airflow ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker-compose logs airflow-webserver
docker-compose logs airflow-scheduler

# RÃ©initialiser la base de donnÃ©es
docker-compose down -v
docker-compose up -d
```

### ProblÃ¨me: Pipeline Ã©choue

```bash
# Voir les dÃ©tails de l'erreur
dvc repro -v

# Nettoyer le cache DVC
dvc gc
dvc repro -f  # Force la reproduction
```

## ğŸ“š Ressources

- [Documentation DVC](https://dvc.org/doc)
- [Documentation Apache Airflow](https://airflow.apache.org/docs/)
- [Best Practices MLOps](https://ml-ops.org/)

## ğŸ‘¥ Contributeurs

- MLOps Team

## ğŸ“„ Licence

Ce projet est sous licence MIT.
